---
title: "Michael Hornsby's EDRM 718 Final Project Script"
output: html_notebook
---

```{r include=FALSE}
library(here)
library(tidyverse)
library(ggrepel)
library(scales)
library(readxl)
library(purrr)
library(dplyr)
library(car)
```


Import the three data sets.  (Note: some tidying was completed in Excel previously)

```{r echo=FALSE}
demo <- as.tibble(read_csv(here("data", "job_prep_demo.csv")))

demo

GPA <- as.tibble(read_csv(here("data", "job_prep_GPA.csv")))

GPA

survey <- as.tibble(read_csv(here("data", "job_prep_survey.csv")))

survey
```


Let's check the ID keys.  I want to make sure there is no ID that appears more
than once in the three datasets.

```{r}
check.demo <- demo %>% count(ID)
check.demo %>% filter(n > 1)
```


```{r}
check.survey <- survey %>% count(ID)
check.survey %>% filter(n > 1)
```


```{r}
check.GPA <- GPA %>% count(ID)
check.GPA %>% filter(n > 1)
```

We see that ID 659 appears twice in the GPA dataset. Let's look
at these observations.

```{r}
GPA %>% filter(ID == 659)
```

If the ID was simply a duplicate observation I would only remove one of them.
However, because the two are different, I'm going to remove both to be safe.

```{r}
GPA <- GPA %>% filter(ID != 659)

check.GPA <- GPA %>% count(ID)
check.GPA %>% filter(n > 1)
```

I removed the two observations where the ID was 659.  The number of 
observations in GPA dropped from 739 to 737, and I ran the check
again just to make sure there were no duplicate ID's.

Let's move to examining student GPAs.

```{r}
ggplot(GPA, aes(x = S1GPA, y = S2GPA)) +
  geom_point() +
  labs(title = "Scatterplot of Semester 2 GPA on Semester 1 GPA",
       subtitle = "Figure 1",
       x = "Semester 1 GPA",
       y = "Semester 2 GPA")
```

I would consider this consistant within reason.  The relationship between
semester 2 gpa and semester 1 gpa looks linear.  There looks to be a 
reasonable amount of deviate from what I would picture a best fit line
to be, but no obvious outliers.

Let's highlight the 10 percent largest residuals, and create the
dataset that doesn't have these largest residuals.

```{r}
resid.function(GPA$S1GPA, GPA$S2GPA, 74, GPA$ID)

ggplot(my_data, aes(x = xvar, y = yvar, color = outcome)) +
  geom_point() +
  labs(title = "Scatterplot of Semester 2 GPA on Semester 1 GPA with Highlighted Residuals",
       subtitle = "Figure 2",
       x = "Semester 1 GPA",
       y = "Semester 2 GPA")
```

```{r}
my_data$ID <- my_data$key

GPA <- my_data %>% left_join(GPA, by = "ID")
GPA <- GPA %>% filter(outcome == FALSE)
```


```{r}
ggplot(GPA, aes(x = xvar, y = yvar)) +
  geom_point() +
  labs(title = "Scatterplot of Semester 2 GPA on Semester 1 GPA with Top 10% Residuals Removed",
       subtitle = "Figure 3",
       x = "Semester 1 GPA",
       y = "Semester 2 GPA")
```


Let's calculate GPA for the year

```{r}
GPA$year.GPA <- 
  ((GPA$S1Credits * GPA$S1GPA) + (GPA$S2Credits * GPA$S2GPA)) / (GPA$S1Credits + GPA$S2Credits)
```

Let's reverse score those appropriate survey items!

```{r}
reverse.function(survey, 6, c(4, 9, 12, 13))

survey <- dataset.tot
```

The individual item responses in the output table above remain the same
as in the original data, however the total column at the end factors in 
the reverse score of the items.  Let's left join the total onto the GPA data.

```{r}
survey.tot <- survey[,c(1,16)]
GPA <- survey.tot %>% left_join(GPA, by = "ID")
```

We need to get the subject onto the GPA dataset so the GPA dataset
will be ready for use in all data analysis relevant to our three main
research questions. A left join is used here as well.

```{r}
demo.sub <- demo[,c(1,5)]
GPA <- demo.sub %>% left_join(GPA, by = "ID")
```

The last step for getting the GPA dataset ready for our analysis is to
drop the observations with missing data.

```{r}
GPA <- GPA[complete.cases(GPA),]
```

Alright, we have 478 complete observations in our GPA dataset for which to 
perform out analysis.


Let's start with the research questions regarding whether GPA is
related to optimism about future employement.  Let's start by looking 
at a scatterplot of this relationship with a best fit line.

```{r}
GPA %>%
  ggplot(aes(x = survey.total, y = year.GPA)) +
  geom_point() +
  stat_smooth(method = lm, se = FALSE) +
  labs(title = "Scatter Plot of Senior Year GPA on Optimism About Future",
       subtitle = "Figure 4",
       x = "Optimism About Future",
       y = "Senior Year GPA")
```



```{r}
GPAonOPT.mod <- lm(year.GPA ~ survey.total, data = GPA)
summary(GPAonOPT.mod)
```

Well, we see that in our model that survey.total has p-value of 0.672 that is
not significant at any reasonable alpha level.  (I did briefly explore a 
higher order relationship just to check, but that wasn't helpful.) 
I cannot conclude that senior year GPA is related to degree of 
optimism about future employement.
Considering we have to use these two variables for further research questions,
I want to check a qqplot for both of these variables.

```{r}
GPA %>%
  ggplot() +
  geom_qq(aes(sample = survey.total)) +
  labs(title = "QQ-plot for Survey Total",
       subtitle = "Figure 5")

GPA %>%
  ggplot() +
  geom_qq(aes(sample = year.GPA)) +
  labs(title = "QQ-plot for Senior Year GPA",
       subtitle = "Figure 6")
```

Well, neither of these look spectacular, but I think it is safe enough
to continue with our analysis regarding the rest of the research questions.
Let's look to see if there is an interaction effect between
the degree of optimism and subject.

```{r}
model.interaction <- aov(GPA$year.GPA ~ GPA$survey.total*GPA$Subject)
Anova(model.interaction)

model.maineffects <- aov(GPA$year.GPA ~ GPA$survey.total+GPA$Subject)
Anova(model.maineffects)
```

The p-values here are all disappointing.  None of these p-value are
significant at any reasonable alpha level.  This would suggest that 
not only is the interaction between optimism and subject not significant, 
neither of the main effects are significant predictors of senior year
GPA either. Let's look at a plot just to make sure.

```{r}
GPA %>%
  ggplot(aes(x = survey.total, y = year.GPA, color = Subject)) +
  geom_point(aes(color = Subject)) +
  stat_smooth(method = lm, se = FALSE) +
  labs(title = "Senior Year GPA on Optimism About Future by Subject",
       subtitle = "Figure 7",
       x = "Optimism About Future",
       y = "Senior Year GPA")
```

The plot looks about as expected after the ANCOVA results and knowing what the 
first scatterplot looked like.  The relationship between senior year GPA and
optimism about the future is fairly consistant for all categories of desciplines.

Let's look at boxplots for levels of optimism about the future for each subject
before we look at the ANOVA.

```{r}
GPA %>%
  ggplot(aes(x = Subject, y = survey.total)) +
  geom_boxplot() +
  labs(title = "Boxplots of Optimism about Future by Subject",
       subtitle = "Figure 8",
       x = "Subject",
       y = "Survey Total")
```


There does look to be some differences here.
I think we can safely assume our assumptions are met here.
Survey total looked close enough to normal and our variances look mostly
equal among subjects. Let's run the ANOVA and see what happens.

```{r}
my.anova <- aov(survey.total ~ Subject, data = GPA)
my.anova.result <- anova(my.anova)
my.anova.result
```

Well, our omnibus test here has a significant p-value at the alpha = 0.05 
confidence level.  This would suggest that at least one subject mean is 
different than the others.  Let's look at all of our pairwise comparisons
while keeping out family-wise confidence level at 95%.

```{r}
TukeyHSD(my.anova)
```

These pairwise comparisons echo what is demonstrated in the boxplots above.
Applied and formal sciences have the highest optimism about the future, with
humanities having much lower optimist about the future.
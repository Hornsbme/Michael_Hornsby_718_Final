---
title: "Michael Hornsby's EDRM 718 Final Project Script"
output: html_notebook
---

```{r include=FALSE}
library(here)
library(tidyverse)
library(ggrepel)
library(scales)
library(readxl)
library(purrr)
library(dplyr)
library(car)
```


Import the three data sets.  (Note: some tidying was completed in Excel previously)

```{r echo=FALSE}
demo <- as.tibble(read_csv(here("data", "job_prep_demo.csv")))

demo

GPA <- as.tibble(read_csv(here("data", "job_prep_GPA.csv")))

GPA

survey <- as.tibble(read_csv(here("data", "job_prep_survey.csv")))

survey
```


Let's check the ID keys.  I want to make sure there is no ID that appears more
than once in the three datasets.

```{r}
check.demo <- demo %>% count(ID)
check.demo %>% filter(n > 1)
```


```{r}
check.survey <- survey %>% count(ID)
check.survey %>% filter(n > 1)
```


```{r}
check.GPA <- GPA %>% count(ID)
check.GPA %>% filter(n > 1)
```

We see that ID 659 appears twice in the GPA dataset. Let's look
at these observations.

```{r}
GPA %>% filter(ID == 659)
```

If the ID was simply a duplicate observation I would only remove one of them.
However, because the two are different, I'm going to remove both to be safe.

```{r}
GPA <- GPA %>% filter(ID != 659)

check.GPA <- GPA %>% count(ID)
check.GPA %>% filter(n > 1)
```

I removed the two observations where the ID was 659.  The number of 
observations in GPA dropped from 739 to 737, and I ran the check
again just to make sure there were no duplicate ID's.

Let's move to examining student GPAs.

```{r}
ggplot(GPA, aes(x = S1GPA, y = S2GPA)) +
  geom_point() +
  labs(title = "Scatterplot of Semester 2 GPA on Semester 1 GPA",
       x = "Semester 1 GPA",
       y = "Semester 2 GPA")
```

I would consider this consistant within reason.  The relationship between
semester 2 gpa and semester 1 gpa looks linear.  There looks to be a 
reasonable amount of deviate from what I would picture a best fit line
to be, but no obvious outliers.

Let's highlight the 10 percent largest residuals, and create the
dataset that doesn't have these largest residuals.

```{r}
resid.function(GPA$S1GPA, GPA$S2GPA, 74, GPA$ID)

ggplot(my_data, aes(x = xvar, y = yvar, color = outcome)) +
  geom_point() +
  labs(title = "Scatterplot of Semester 2 GPA on Semester 1 GPA with Highlighted Residuals",
       x = "Semester 1 GPA",
       y = "Semester 2 GPA")
```

```{r}
my_data$ID <- my_data$key

GPA <- my_data %>% left_join(GPA, by = "ID")
GPA <- GPA %>% filter(outcome == FALSE)
```


```{r}
ggplot(GPA, aes(x = xvar, y = yvar)) +
  geom_point() +
  labs(title = "Scatterplot of Semester 2 GPA on Semester 1 GPA with Top 10% Residuals Removed",
       x = "Semester 1 GPA",
       y = "Semester 2 GPA")
```


Let's calculate GPA for the year

```{r}
GPA$year.GPA <- 
  ((GPA$S1Credits * GPA$S1GPA) + (GPA$S2Credits * GPA$S2GPA)) / (GPA$S1Credits + GPA$S2Credits)
```

Let's reverse score those appropriate survey items!

```{r}
reverse.function(survey, 6, c(4, 9, 12, 13))

survey <- dataset.tot
```

The individual item responses in the output table above remain the same
as in the original data, however the total column at the end factors in 
the reverse score of the items.  Let's left join the total onto the GPA data.

```{r}
survey.tot <- survey[,c(1,16)]
GPA <- survey.tot %>% left_join(GPA, by = "ID")
```

Finally, we need to get the subject onto the GPA dataset so the GPA dataset
will be ready for use in all data analysis relevant to our three main
research questions. A left join is used here as well.

```{r}
demo.sub <- demo[,c(1,5)]
GPA <- demo.sub %>% left_join(GPA, by = "ID")
```

